\chapter{Abstrations of Jaseci}
\minitoc
\section{Graphs, the Friend that Never Gets Invited to the Party}
There's something quite strange that has happend with our \gls{common languages} over the years, ...decades. When you look at it, almost every data structure we programmers use to solve problems can be modeled formally as a graph, or a special case of a graph, (save perhaps hash tables). Think about it, stacks, lists, queues, trees, heaps, and yes, even graphs, can be modeled with graphs. But, low and behold, no common language ustilizes the formal semantics of a graph as its first order abstraction for data or memory. I mean, isn't it a bit odd that practically every data structure covered in the language-agnostic classic foundational work \textit{Introduction to Algorithms}~\cite{intro_to_algo} can most naturally be be reasoned about as a graph, yet none of the common languages have built in and be designed around this primitive. I submit that the graph semantic is insanely rich, very nice for us humans to reason about, and, most importantly for the purpose of Jaseci, is inherently well suited for the conceptualization and reasoning about computational problems, especially AI problems.
\par
There are a few arguments that may pop into mind at this point of my conjecture.
\begin{itemize}
    \item ``Well there are graph libraries in my favorite language that implement graph symantics, why would I need a language to force the concept upon me?''
          or
    \item ``Duh! Interacting with all data and memory through graphical abstractions will make the language ssllooowww as hell since memory in hardware is essitially a big array, what is this dude talking about!?!?''
\end{itemize}
\par
For the former of these two challenges, I counter with two points. First, the core design languages are always based upon their inherent abstractions. With graphs not being one such abstraction, the language's design will not be optimized to empower programmers to nimbly do gymnastics with rich language symantics that correspond to the rich semantics graphs offer (You'll see what I mean in later chapters).
\par
For the latter question, I'd respond, ``Have you SEEN the kind of abstractions in modern languages!?!? It's rediculous, lets look at python dictionaries, actually scratch that, lets keep it simple and look at dynamic typing in general. The runtime complexity to support dynamic typing is most certainly higher than what would be needed to support graph symantics. Duh right back at'ya!''
\subsection{Yes, But What Kind of Graphs}

There are many categories of graphs to consider when thinking about the abstractions to support in Jaseci. There are rules to be defined as to the availabe semantics of the graphs. Should all graphs be \gls{directed graphs}, should we allow the creation of \gls{undirected graphs}, what about parallel edges or \gls{multigraphs}, are those explicitly expressible or discouraged / banned, can we express \gls{hypergraphs}, and what combination of these graphical sematics should be able to be manifested and manipulated through the programming model. At this point I can feel your eyes getting droopy and your mind moving into that intermediary state between concious and sleeping, so let me cut to the answer.
\par
\printfigGraphTypes
In Jaseci, we elect to assume the following semantics:
\begin{enumerate}
    \item Graphs are directed (as per Figure~\ref{fig:directedgraph}) with a special case of a doubly directed edge type which can be utilized practically as an undirected edge (imagine fusing the two edges between nodes 3 and 4 in the figure).
    \item Both nodes and edges have their own distinct identities (i,e. an edge isn't representable as a pairing of two nodes). This point is important as both nodes and edges can have \gls{contexts}.
    \item Multigraphs (i.e., parallel edges) are allowed, including self-loop edges (as per Figure~\ref{fig:multigraph}).
    \item Graphs are not required to be acyclic.
    \item No hypergraphs, as I wouldn't want Jaseci programmers heads to explode.

\end{enumerate}
\emph{As an aside, I would describe Jaseci graphs as strictly unstrict directed multigraphs that leverages the semantics of parallel edges to create a laymans `undirected edge' by shorthanding two directed edges pointed in opposite directions between the same two nodes.}
\par
\begin{nerd}
    I'd formally describe a Jaseci Graph as an $7$-tuple $(N,E,C,s,t,c_N,c_E)$, where
    \begin{enumerate}
        \item $N$ is the set of nodes in a graph
        \item $E$ is the set of edges in a graph
        \item $C$ is the set of all contexts
        \item $s$: $E \rightarrow V$, maps the source node to an edge
        \item $t$: $E \rightarrow V$,  maps the target node to an edge
        \item $c_N$: $N \rightarrow C$, maps nodes to contexts
        \item $c_E$: $E \rightarrow C$, maps edges to contexts
    \end{enumerate}
    An undriected edge can then be formed with a pair of edges $(x, y)$ if three conditions are met,
    \begin{enumerate}
        \item $x, y \in E$
        \item $s(x) = t(y)$, and $s(y) = t(x)$
        \item $c_E(x) = c_E(y)$
    \end{enumerate}
\end{nerd}
\par
If you happend to have read that formal definition and didn't enter deep comatose you may be wondering ``Whoa, what was that context stuff that came outta nowhere! What's this guy trying to do here, sneaking a new concept in as if it was already introduced and described.''
\par
Worry not friend, lets discuss.
\subsection{Putting it All Into Context}

A key principle of Jaseci is to reshape and reimagine how we view data and memory. We do so by fusing the concept of data with the intuitive and rich semantics of graphs as the lowest level primitive to view memory.

\begin{nerd}
    A context is a representation of data that can be expressed simply as a $3$-tuple $(\sum_K,\sum_V,p_K)$, where
    \begin{enumerate}
        \item $\sum_K$ is a finite alphabet of keys
        \item $\sum_V$ is a finite alphabet of values
        \item $p_K$ is the pairing of keys to values
    \end{enumerate}
\end{nerd}
\section{Walkers}
One of the most important abstractions introduced in Jaseci is that of the \texttt{walker}.
The semantics of this abstraction is unlike any that has existed in any programming language before.

In a nutshell, a walker is a unit of execution that retains state (its local scope) as it travels over a graphs.
Walkers `walk' from node to node in the graph and executing its body.

The walker's body is specified with an opening and closing braces (\texttt{ \{ \} }) and is executed to completion on each node it lands on.
In this sense a walker iterates while spooling through a sequence of nodes that it `takes' using the \lstinline{take} keyword.
We call each of these iterations \emph{node-bound iterations}.

Variables declared in a walker's body takes two forms: its \emph{context variables}, those that retain state as it travels from node to node in a graph, and its \emph{local variables}, those that are reinitialized for each node-bound iterations.

Walkers present a new way of thinking about programmatic execution distinct from the near-ubiquitous function based asbtraction in other languages.
Instead of a functions scope being temporally pushed onto an ever increasing stack as functions call other functions.
Scopes can be spacially laid out on a graph and walkers can hop around the graph taking its scope with it.
A key difference in this model is in its introduction of data spacial problem solving.
In the former function-based model scopes become unaccessible upon the sub-call of a function until that function returns.
In contrast, walkers can access any scope at any time in a modular way.

When solving problems with walkers, a developer can think of that walker as a little self-contained robot or agent that can retain context as it spacially moves about a graph, interacting with the context in nodes and edges of that graph.

In addition to the introduction of the \lstinline{take} command to support new types of control flow for node-bound iterations. The keywords and semantics of \lstinline{disengage}, \lstinline{skip}, and \lstinline{ignore} are also introduced. These instruct walkers to stop walking the graph, skip over a node for execution, and ignore certain paths of the graph.
These semantics are describe in more detail later in the book.

[Entrypoints to a jac program, init recognized as default]

\section{Abilities}

Nodes, edges, and walkers can have \texttt{abilities}.
The body of an ability is specified with an opening and closing braces (\texttt{ \{ \} }) within the specification of a node, edge, or walker and specify a unit of execution.

Abilities are most closely analogous to methods in a traditional object oriented program, however they do not have the same semantics of a traditional function.
An ability can only interact within the scope of context and local variables of the node/edge/walker for which it is affixed and do not have a \texttt{return} semantic. (Though it is important to note, that abilities can always access the scope of the executing walker using the \lstinline{visitor} special variable as described below)

When using abilities, a developer can think of these as self-contained in-memory/in-data compute operations.

\section{\texttt{here} and \texttt{visitor}}

At every execution point in a Jac/Jaseci program there are two scopes visible, that of the walker, and that of the node it is executing on.
These contexts can be referenced with the special variables \lstinline{here} and \lstinline{visitor} respectively.
Walkers use \lstinline{here} to refer to the context of the node it is currently executing on, and abilities can use \lstinline{visitor} to refer to the context of the current walker executing.

\section{Actions}

Actions enables bindings to functionality specified outside of Jac/Jaseci and behave as function calls with returns.
These are analogous to library calls in traditional languages.
This external functionality in practice takes the form of direct binding to python implementations that are packaged up as a Jaseci action library.

\begin{nerd}
    Note: This action interface is the abstraction that allows Jaseci to do it's fancy inter-machine optimizations, auto-scaling, auto-componentization etc.
\end{nerd}