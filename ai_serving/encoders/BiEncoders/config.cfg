[TRAIN_PARAMETERS]
max_contexts_length = 128
max_response_length = 64
train_batch_size = 32
eval_batch_size = 2
max_history = 4
learning_rate = 5e-5
weight_decay = 0.1
warmup_steps = 2000
adam_epsilon = 1e-8
max_grad_norm = 1.0
num_train_epochs = 10
seed = 12345
gradient_accumulation_steps = 1
fp16 = False
fp16_opt_level = O1
gpu = 0

[MODEL_PARAMETERS]
architecture = bi
shared = True
model_name = bert-base-uncased
poly_m = 16

