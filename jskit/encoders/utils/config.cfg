[TRAIN_PARAMETERS]
max_contexts_length = 128
max_response_length = 64
train_batch_size = 32
eval_batch_size = 2
max_history = 4
learning_rate = 0.00005
weight_decay = 0.1
warmup_steps = 2000
adam_epsilon = 0.00000008
max_grad_norm = 1.0
num_train_epochs = 2
seed = 12345
gradient_accumulation_steps = 1
fp16 = False
fp16_opt_level = O1
gpu = 0
basepath = log_output

[MODEL_PARAMETERS]
architecture = bi
shared = False
model_name = bert-base-uncased
poly_m = 16

