# [DEPRECATED] How to add an AI service to Jaseci
### This section needs to be update with the latest action interface.

Jaseci AI services are regular HTTP services that provide some machine learning / AI functionality via API endpoints.

In this example, we are going to create a custom [fastText](https://fasttext.cc/) intent classifier and expose its classification capabilities to Jaseci.

**NOTE:** We will be using a Docker-ized approach to maintain portability. Learn about Docker [here](https://www.docker.com/).

### 1. Generate AI service scaffolding

The first step is to generate the scaffolding you'll need to set up your AI service.

### 2. Prepare AI service following Jaseci patterns

The next step is to set up the HTTP service using Jaseci patterns and add support for the desired functionality.

For this we will use:
- [Python](https://www.python.org/)
- [Flask](https://flask.palletsprojects.com/en/2.0.x/)
- [fastText](https://fasttext.cc/)

This is set up to:
- Transform the training data in `training_data.json` to the format fastText expects.
- Train and save a model with that data.
- Provide an endpoint to run predictions on the trained model.

#### Docker Container Architecture
- Based on [Python 3.7 image](https://hub.docker.com/_/python)
- Installs fastText module from [GitHub](https://github.com/facebookresearch/fastText#building-fasttext-for-python)
- Installs other requirements from `requirements.txt`
- The `fasttext-classifier-up` script in `fasttext_classifier.yaml` downloads the required code to the container and starts the AI service.

### 3. Configure the YAML file for your AI service

For this step, most of the YAML configuration would have already been generated by the `create_ai_service.sh` script.

In this case it is called `fasttext_classifier.yaml`.

### 4. Create Jaseci action for the service

Jaseci actions let you add the functionality from an external service to Jaseci itself. These actions can then be used in your Jac code.

This is how we'll be adding support for the fastText classifier service we just set up to Jaseci.

- Add an entry for the new service in `jaseci_core/jaseci/actions/module/ai-serving.config.ini`
  - ```
    [FASTTEXT_CLF]
    url: http://fasttext-classifier:4675/fasttext-classifier/
    ```
  - The first mention of `fasttext-classifier` is the container's hostname
  - The second is the endpoint route set up in `fasttext_classifier.py`
  - Notice that the service port (`4675`) that was configured previously in `fasttext_classifier.py` and `fasttext_classifier.yaml` is also used here.
- Create a file with functions for each supported action in `jaseci_core/jaseci/actions/module`
  - Ex: `fasttext_classifier_actions.py`
  - Use `AIServingAPI` to access the service
- Create another file in `jaseci_core/jaseci/actions` to expose those actions
  - Ex: `fasttext_classifier.py`

The `can fasttext_classifier.predict;` action is now available to Jac code.

### 5. Write tests for the created action

To ensure that our newly added action functions correctly and continues to function as we make changes, we will add tests to define expected behavior.

Those tests can be added to the `jaseci_core/jaseci/tests` directory.


### End

Now you're ready to use the `fasttext_classifier` AI service in Jaseci or create your own.
